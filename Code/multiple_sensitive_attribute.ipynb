{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from collections import Counter\n",
    "\n",
    "# Models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Bias\n",
    "\n",
    "import aif360\n",
    "from aif360.algorithms.preprocessing import DisparateImpactRemover, Reweighing\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "from aif360.datasets import StandardDataset \n",
    "\n",
    "pd.options.mode.chained_assignment = None \n",
    "np.set_printoptions(suppress=True)\n",
    "pd.set_option('display.float_format', lambda x: '%.7f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = pd.read_csv(r\"C:\\Users\\bassa\\Desktop\\Natwest\\Dataset\\adult.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale the elements of the column to a number\n",
    "def rescale_elements(df, feature):\n",
    "    x=df[feature].value_counts()\n",
    "    item_type_mapping = {}\n",
    "    item_list = x.index\n",
    "    for i in range(0,len(item_list)):\n",
    "        item_type_mapping[item_list[i]] = i\n",
    "    df[feature]=df[feature].map(lambda x:item_type_mapping[x])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 46447 entries, 0 to 46446\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count  Dtype\n",
      "---  ------           --------------  -----\n",
      " 0   age              46447 non-null  int64\n",
      " 1   workclass        46447 non-null  int64\n",
      " 2   fnlwgt           46447 non-null  int64\n",
      " 3   education        46447 non-null  int64\n",
      " 4   educational-num  46447 non-null  int64\n",
      " 5   marital-status   46447 non-null  int64\n",
      " 6   occupation       46447 non-null  int64\n",
      " 7   relationship     46447 non-null  int64\n",
      " 8   race             46447 non-null  int64\n",
      " 9   gender           46447 non-null  int64\n",
      " 10  capital-gain     46447 non-null  int64\n",
      " 11  capital-loss     46447 non-null  int64\n",
      " 12  hours-per-week   46447 non-null  int64\n",
      " 13  native-country   46447 non-null  int64\n",
      " 14  income           46447 non-null  int64\n",
      "dtypes: int64(15)\n",
      "memory usage: 5.3 MB\n"
     ]
    }
   ],
   "source": [
    "# rescale race (white = 0, black = 1) after dropping: Asian-Pac-Islander, Amer-Indian-Eskimo, Other\n",
    "df = df_original[df_original['race'].isin(['White', 'Black'])]\n",
    "df['race'][df['race'] == 'White'] = 0\n",
    "df['race'][df['race'] == 'Black'] = 1\n",
    "\n",
    "# rescale sex (sex : male = 0 , female = 1)\n",
    "df['gender'][df['gender'] == 'Male'] = 0\n",
    "df['gender'][df['gender'] == 'Female'] = 1\n",
    "\n",
    "# rescale marital status (Married-civ-spouse = 0, Never-married = 1) after dropping 'others'\n",
    "df['marital-status'][df['marital-status'].isin(['Married-civ-spouse', 'Married-spouse-absent', 'Married-AF-spouse'])] = 0\n",
    "df['marital-status'][df['marital-status'].isin(['Never-married', 'Divorced', 'Separated', 'Widowed'])] = 1\n",
    "\n",
    "# rescale income (>50K = 0, <=50K = 1)\n",
    "df['income'][df['income'] == '>50K'] = 0\n",
    "df['income'][df['income'] == '<=50K'] = 1\n",
    "\n",
    "# rescale native-country (United-States = 0, any other country = 1)\n",
    "df['native-country'][df['native-country'] == 'United-States'] = 0\n",
    "df['native-country'][df['native-country'] != 0] = 1\n",
    "\n",
    "# rescale education \n",
    "df = rescale_elements(df, 'education')\n",
    "\n",
    "# rescale relationship\n",
    "df = rescale_elements(df, 'relationship')\n",
    "\n",
    "# rescale occupation\n",
    "df = rescale_elements(df, 'occupation')\n",
    "\n",
    "# rescale workclass\n",
    "df = rescale_elements(df, 'workclass')\n",
    "\n",
    "# Transform the object in integers and reset the index\n",
    "df = df.apply(pd.to_numeric).reset_index(drop=True)\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fair_metrics(data, y_pred, target, protected_attribute_names) :\n",
    "    dataset = StandardDataset(data, \n",
    "                          label_name=target, \n",
    "                          favorable_classes=[0], \n",
    "                          protected_attribute_names=protected_attribute_names, \n",
    "                          privileged_classes=[[0]])\n",
    "\n",
    "    dataset_pred = dataset.copy()\n",
    "    dataset_pred.labels = y_pred\n",
    "        \n",
    "    attr = dataset_pred.protected_attribute_names[0]\n",
    "    \n",
    "    idx = dataset_pred.protected_attribute_names.index(attr)\n",
    "    privileged_groups =  [{attr:dataset_pred.privileged_protected_attributes[idx][0]}] \n",
    "    unprivileged_groups = [{attr:dataset_pred.unprivileged_protected_attributes[idx][0]}] \n",
    "\n",
    "    classified_metric = ClassificationMetric(dataset, dataset_pred, unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
    "\n",
    "    metric_pred = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
    "\n",
    "    result = {f'disparate_impact_{protected_attribute_names[0]}': metric_pred.disparate_impact(),\n",
    "              f'statistical_parity_difference_{protected_attribute_names[0]}': metric_pred.statistical_parity_difference(),\n",
    "              f'equal_opportunity_difference_{protected_attribute_names[0]}': classified_metric.equal_opportunity_difference()}\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mitigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Reweighing_1(X, y, A):\n",
    "    # X: independent variables (2-d pd.DataFrame)\n",
    "    # y: the dependent variable (1-d np.array)\n",
    "    # A: the name of the sensitive attributes (list of string)\n",
    "    groups_class = {}\n",
    "    group_weight = {}\n",
    "    for i in range(len(y)):\n",
    "        key_class = tuple([X[a][i] for a in A]+[y[i]])\n",
    "        key = key_class[:-1]\n",
    "        if key not in group_weight:\n",
    "            group_weight[key]=0\n",
    "        group_weight[key]+=1\n",
    "        if key_class not in groups_class:\n",
    "            groups_class[key_class]=[]\n",
    "        groups_class[key_class].append(i)\n",
    "    class_weight = Counter(y)\n",
    "    sample_weight = np.array([1.0]*len(y))\n",
    "    for key in groups_class:\n",
    "        weight = class_weight[key[-1]]*group_weight[key[:-1]]/len(groups_class[key])\n",
    "        for i in groups_class[key]:\n",
    "            sample_weight[i] = weight\n",
    "    # Rescale the total weights to len(y)\n",
    "    sample_weight = sample_weight * len(y) / sum(sample_weight)\n",
    "    return sample_weight\n",
    "\n",
    "def FairBalance(X, y, A):\n",
    "    # X: independent variables (2-d pd.DataFrame)\n",
    "    # y: the dependent variable (1-d np.array)\n",
    "    # A: the name of the sensitive attributes (list of string)\n",
    "    groups_class = {}\n",
    "    group_weight = {}\n",
    "    for i in range(len(y)):\n",
    "        key_class = tuple([X[a][i] for a in A] + [y[i]])\n",
    "        key = key_class[:-1]\n",
    "        if key not in group_weight:\n",
    "            group_weight[key] = 0\n",
    "        group_weight[key] += 1\n",
    "        if key_class not in groups_class:\n",
    "            groups_class[key_class] = []\n",
    "        groups_class[key_class].append(i)\n",
    "    sample_weight = np.array([1.0]*len(y))\n",
    "    for key in groups_class:\n",
    "        weight = group_weight[key[:-1]]/len(groups_class[key])\n",
    "        for i in groups_class[key]:\n",
    "            sample_weight[i] = weight\n",
    "    # Rescale the total weights to len(y)\n",
    "    sample_weight = sample_weight * len(y) / sum(sample_weight)\n",
    "    return sample_weight\n",
    "\n",
    "def FairBalanceVariant(X, y, A):\n",
    "    # X: independent variables (2-d pd.DataFrame)\n",
    "    # y: the dependent variable (1-d np.array)\n",
    "    # A: the name of the sensitive attributes (list of string)\n",
    "    groups_class = {}\n",
    "    for i in range(len(y)):\n",
    "        key_class = tuple([X[a][i] for a in A] + [y[i]])\n",
    "        if key_class not in groups_class:\n",
    "            groups_class[key_class] = []\n",
    "        groups_class[key_class].append(i)\n",
    "    sample_weight = np.array([1.0]*len(y))\n",
    "    for key in groups_class:\n",
    "        weight = 1.0/len(groups_class[key])\n",
    "        for i in groups_class[key]:\n",
    "            sample_weight[i] = weight\n",
    "    # Rescale the total weights to len(y)\n",
    "    sample_weight = sample_weight * len(y) / sum(sample_weight)\n",
    "    return sample_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 2",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_34024/3504661616.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefault_seed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0msample_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFairBalanceVariant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"gender\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"race\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_34024/2912322415.py\u001b[0m in \u001b[0;36mFairBalanceVariant\u001b[1;34m(X, y, A)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[0mgroups_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[0mkey_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey_class\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgroups_class\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[0mgroups_class\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey_class\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_34024/2912322415.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[0mgroups_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[0mkey_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey_class\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgroups_class\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[0mgroups_class\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey_class\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    940\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1049\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m         \u001b[1;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1051\u001b[1;33m         \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3361\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3363\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "x = df.drop(['income'], axis = 1)\n",
    "y = df['income'] \n",
    "default_seed = 1\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=default_seed)\n",
    "\n",
    "sample_weight = FairBalanceVariant(x_train, y_train, [\"gender\", \"race\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self, data, treatment=\"None\", inject = None):\n",
    "    #  Load data\n",
    "    self.data, self.A = load(data)\n",
    "    # Separate independent variables and dependent variables\n",
    "    independent = self.data.keys().tolist()\n",
    "    dependent = independent.pop(-1)\n",
    "    self.X = self.data[independent]\n",
    "    self.y = np.array(self.data[dependent])\n",
    "    self.treatment = treatment\n",
    "    self.inject = inject\n",
    "    if treatment == \"FERMI\":\n",
    "        self.clf = FERMI()\n",
    "    else:\n",
    "        self.clf = LogisticRegression(max_iter=100000)\n",
    "\n",
    "def one_exp(self):\n",
    "    X_train, X_test, y_train, y_test = self.train_test_split(test_size=0.5)\n",
    "    #########################################\n",
    "    self.data_preprocess(X_train)\n",
    "    sample_weight = self.treat(X_train, y_train)\n",
    "    self.fit(X_train, y_train, sample_weight)\n",
    "    m_train = Metrics(self.clf, X_train, y_train, self.A, self.preprocessor)\n",
    "    m_test = Metrics(self.clf, X_test, y_test, self.A, self.preprocessor)\n",
    "    return m_train, m_test\n",
    "\n",
    "def fit(self, X, y, sample_weight=None):\n",
    "    X_train_processed = self.preprocessor.fit_transform(X)\n",
    "    if type(self.clf) == FERMI:\n",
    "        S = []\n",
    "        groups = {}\n",
    "        count = 0\n",
    "        for i in range(len(y)):\n",
    "            group = tuple([X[a][i] for a in self.A])\n",
    "            if group not in groups:\n",
    "                groups[group] = count\n",
    "                count += 1\n",
    "            S.append(groups[group])\n",
    "        S = np.array(S)\n",
    "        self.clf.fit(X_train_processed, y, S, sample_weight=sample_weight)\n",
    "    else:\n",
    "        self.clf.fit(X_train_processed, y, sample_weight=sample_weight)\n",
    "\n",
    "def data_preprocess(self, X):\n",
    "    numerical_columns_selector = selector(dtype_exclude=object)\n",
    "    categorical_columns_selector = selector(dtype_include=object)\n",
    "\n",
    "    numerical_columns = numerical_columns_selector(X)\n",
    "    categorical_columns = categorical_columns_selector(X)\n",
    "\n",
    "    categorical_preprocessor = OneHotEncoder(handle_unknown = 'ignore')\n",
    "    numerical_preprocessor = StandardScaler()\n",
    "    self.preprocessor = ColumnTransformer([\n",
    "        ('OneHotEncoder', categorical_preprocessor, categorical_columns),\n",
    "        ('StandardScaler', numerical_preprocessor, numerical_columns)])\n",
    "\n",
    "def treat(self, X_train, y_train):\n",
    "    if self.treatment == \"Reweighing\":\n",
    "        sample_weight = Reweighing(X_train, y_train, self.A)\n",
    "    elif self.treatment == \"FairBalanceVariant\":\n",
    "        sample_weight = FairBalanceVariant(X_train, y_train, self.A)\n",
    "    elif self.treatment == \"FairBalance\":\n",
    "        sample_weight = FairBalance(X_train, y_train, self.A)\n",
    "    else:\n",
    "        sample_weight = None\n",
    "    return sample_weight\n",
    "\n",
    "def train_test_split(self, test_size=0.5):\n",
    "    # Split training and testing data proportionally across each group\n",
    "    groups = {}\n",
    "    for i in range(len(self.y)):\n",
    "        key = tuple([self.X[a][i] for a in self.A] + [self.y[i]])\n",
    "        if key not in groups:\n",
    "            groups[key] = []\n",
    "        groups[key].append(i)\n",
    "    train = []\n",
    "    test = []\n",
    "    for key in groups:\n",
    "        testing = list(np.random.choice(groups[key], int(len(groups[key])*test_size), replace=False))\n",
    "        training = list(set(groups[key]) - set(testing))\n",
    "        test.extend(testing)\n",
    "        train.extend(training)\n",
    "    X_train = self.X.iloc[train]\n",
    "    X_test = self.X.iloc[test]\n",
    "    y_train = self.y[train]\n",
    "    y_test = self.y[test]\n",
    "    X_train.index = range(len(X_train))\n",
    "    X_test.index = range(len(X_test))\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8723faa727b3454d45029a3f0ac1bbe48db2ba55e14042fadf0a7bf15ec4eb4c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
